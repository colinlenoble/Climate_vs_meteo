{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4e68721",
   "metadata": {},
   "source": [
    "### Notebook Pour une rentrée en sciences 2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d847d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmeteo_requests\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import requests_cache\n",
    "import os\n",
    "from retry_requests import retry\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b1340",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_open_meteo_url(longitude, latitude, year_start, year_end, daily_variables):\n",
    "    \"\"\"\n",
    "    Récupération de l'url de l'API Open-Météo\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    longitude : float\n",
    "        DESCRIPTION.\n",
    "    latitude : float\n",
    "        DESCRIPTION.\n",
    "    year : int\n",
    "        DESCRIPTION.\n",
    "    hourly_variables : list of str or str\n",
    "        DESCRIPTION.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    url : str\n",
    "        DESCRIPTION.\n",
    "\n",
    "    \"\"\"\n",
    "    if isinstance(daily_variables, list):\n",
    "        daily_variables = ','.join(daily_variables)\n",
    "    tod = pd.Timestamp(date.today())\n",
    "    \n",
    "    # Si l'année demandée n'est pas terminée, il faut modifier les périodes requêtées\n",
    "    end_month, end_day = 12, 31\n",
    "    if year_end == tod.year:\n",
    "        end_day = tod.strftime('%d')\n",
    "        end_month = tod.strftime('%m')\n",
    "        \n",
    "    url = 'https://archive-api.open-meteo.com/v1/archive?latitude={}&longitude={}&start_date={}-01-01&end_date={}-{}-{}&daily={}&timezone=Europe%2FBerlin'.format(latitude,longitude,year_start,year_end,end_month,end_day,daily_variables)\n",
    "    # print(url)\n",
    "    return url\n",
    "\n",
    "\n",
    "def open_meteo_historical_data(longitude, latitude, year_start, year_end, daily_variables=[\"snowfall_sum\", \"temperature_2m_max\", \"temperature_2m_min\", \"temperature_2m_mean\"], force=False, save = False):\n",
    "    \"\"\"\n",
    "    Ouverture des fichiers meteo\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    longitude : float\n",
    "        DESCRIPTION.\n",
    "    latitude : float\n",
    "        DESCRIPTION.\n",
    "    year : int\n",
    "        DESCRIPTION.\n",
    "    hourly_variables : str or list of str, optional\n",
    "        DESCRIPTION. The default is ['temperature_2m','direct_radiation_instant'].\n",
    "    force : boolean, optional\n",
    "        DESCRIPTION. The default is False.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    data : pandas DataFrame\n",
    "        DESCRIPTION.\n",
    "\n",
    "    \"\"\"\n",
    "    # TODO : peut-etre mettre un nom de ville en entrée et en faire des nom de sauvegarde plus lisible\n",
    "    if isinstance(daily_variables, list):\n",
    "        daily_variables_str = ','.join(daily_variables)\n",
    "    else:\n",
    "        daily_variables_str = daily_variables\n",
    "        \n",
    "    save_path = os.path.join('data','Open-Meteo')\n",
    "    save_name = '{}_{}_{}_{}.csv'.format(daily_variables_str, year_start, year_end, longitude, latitude)\n",
    "    save_name_units = '{}_{}_{}_{}_units.txt'.format(daily_variables_str, year_start, year_end, longitude, latitude)\n",
    "\n",
    "    if save_name not in os.listdir(save_path) or force:\n",
    "        url = get_open_meteo_url(longitude, latitude, year_start, year_end, daily_variables)\n",
    "        response = requests.get(url)\n",
    "        print(\"Requesting data from Open-Meteo API...\")\n",
    "        import time\n",
    "        time.sleep(10)  # To avoid hitting rate limits\n",
    "        json_data = response.json()\n",
    "        if response.status_code==429:\n",
    "            print(\"Too many requests. Waiting before retrying...\")\n",
    "            return None\n",
    "        data = pd.DataFrame().from_dict(json_data.get('daily'))\n",
    "        data.to_csv(os.path.join(save_path,save_name), index=False)\n",
    "        \n",
    "    data = pd.read_csv(os.path.join(save_path,save_name))\n",
    "    data = data.set_index('time')\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bca783",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref = pd.read_csv(\"data/pref_lat_lon.csv\", sep=\";\")\n",
    "pref[\"lat\"] = pref[\"Geo Point\"].apply(lambda x: float(x.split(\",\")[0]))\n",
    "pref[\"lon\"] = pref[\"Geo Point\"].apply(lambda x: float(x.split(\",\")[1]))\n",
    "pref = pref[['Code INSEE', 'Commune', 'Service', 'lat', 'lon']]\n",
    "# pref = pref[pref.Service == 'Préfecture']\n",
    "\n",
    "seuils_df = pd.read_csv(\"data/seuils_canicules.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd85db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plot(df, col, pref_name, out_path=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    dict_col = {\n",
    "        'temperature_2m_mean': 'Tempature moyenne 2m (°C)',\n",
    "        'snowfall_sum': 'Chute de neige annuelle (cm)',\n",
    "        'canicule': 'Nombre de jours de canicule',\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(df['year'], df[col], label=col)\n",
    "    plt.title(f\"{dict_col.get(col, col)} : {pref_name}\")\n",
    "    plt.xlabel(\"Année\")\n",
    "    plt.ylabel(dict_col.get(col, col))\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    if out_path is not None:\n",
    "        plt.savefig(out_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee93bf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = pref[pref.Service != 'Sous-préfecture'].lon.to_list()\n",
    "lats = pref[pref.Service != 'Sous-préfecture'].lat.to_list()\n",
    "communes = pref[pref.Service != 'Sous-préfecture'].Commune.to_list()\n",
    "pref['Code INSEE'] = pref['Code INSEE'].astype(str).str.zfill(5)\n",
    "code_insee = pref[pref.Service != 'Sous-préfecture']['Code INSEE'].to_list()\n",
    "year_start, year_end = 1950, 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30b04da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping Orléans (45234) as already processed.\n",
      "Skipping Blois (41018) as already processed.\n",
      "Skipping Carcassonne (11069) as already processed.\n",
      "Skipping Saint-Lô (50502) as already processed.\n",
      "Skipping Foix (09122) as already processed.\n",
      "Skipping Tarbes (65440) as already processed.\n",
      "Skipping Nevers (58194) as already processed.\n",
      "Skipping Bar-le-Duc (55029) as already processed.\n",
      "Skipping Lyon (69123) as already processed.\n",
      "Skipping Le Mans (72181) as already processed.\n",
      "Skipping Charleville-Mézières (08105) as already processed.\n",
      "Skipping Nice (06088) as already processed.\n",
      "Skipping Périgueux (24322) as already processed.\n",
      "Skipping Epinal (88160) as already processed.\n",
      "Skipping Beauvais (60057) as already processed.\n",
      "Skipping Limoges (87085) as already processed.\n",
      "Skipping Bobigny (93008) as already processed.\n",
      "Skipping Caen (14118) as already processed.\n",
      "Skipping Albi (81004) as already processed.\n",
      "Processing Châlons-en-Champagne (51108)\n",
      "Requesting data from Open-Meteo API...\n",
      "Processing Guéret (23096)\n",
      "Requesting data from Open-Meteo API...\n",
      "Processing Tulle (19272)\n",
      "Requesting data from Open-Meteo API...\n",
      "Too many requests. Waiting before retrying...\n",
      "Skipping Tulle (19272) due to request issues.\n"
     ]
    }
   ],
   "source": [
    "df_final = []\n",
    "for i in range(len(lons)):\n",
    "    lon, lat, name, code = lons[i], lats[i], communes[i], code_insee[i]\n",
    "    df_yearly = pd.read_csv(os.path.join('data',f'all_prefectures_{year_start}_{year_end}_yearly.csv'))\n",
    "    if name in df_yearly['Commune'].values:\n",
    "        print(f\"Skipping {name} ({code}) as already processed.\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Processing {name} ({code})\")\n",
    "        dept = code[:2]\n",
    "        data = open_meteo_historical_data(lon, lat, year_start, year_end, \n",
    "                                        daily_variables=[\"snowfall_sum\", \"temperature_2m_max\", \"temperature_2m_min\", \"temperature_2m_mean\"], force=False, save=False)\n",
    "        if data is None:\n",
    "            print(f\"Skipping {name} ({code}) due to request issues.\")\n",
    "            break\n",
    "        data['Commune'] = name\n",
    "        data['Departement'] = dept\n",
    "        data = data.reset_index()\n",
    "        data = data.merge(seuils_df, left_on='Departement', right_on='dep', how='left')\n",
    "        data['canicule'] = (data['temperature_2m_max'] >= data['smax'])&(data['temperature_2m_min'] >= data['smin'])\n",
    "        data = data.set_index('time')\n",
    "        data = data.resample('YS').agg({'canicule':'sum', \n",
    "                                                    'temperature_2m_mean':'mean',\n",
    "                                                    'snowfall_sum':'sum', \n",
    "                                                    'Commune':'first',\n",
    "                                                    'Departement':'first'})\n",
    "        data['year'] = data.index.year\n",
    "        os.makedirs(f\"output/Dept_{dept}\", exist_ok=True)\n",
    "        make_plot(data, 'temperature_2m_mean', name, out_path=f\"output/Dept_{dept}/{code}_temperature_2m_mean.png\")\n",
    "        make_plot(data, 'snowfall_sum', name, out_path=f\"output/Dept_{dept}/{code}_snowfall_sum.png\")\n",
    "        make_plot(data, 'canicule', name, out_path=f\"output/Dept_{dept}/{code}_canicule.png\")\n",
    "        df_yearly = pd.concat([df_yearly, data.reset_index()])\n",
    "        df_yearly.to_csv(os.path.join('data',f'all_prefectures_{year_start}_{year_end}_yearly.csv'), index=False)\n",
    "\n",
    "# df_final = pd.concat(df_final)\n",
    "# os.makedirs(os.path.join('data','Open-Meteo'), exist_ok=True)\n",
    "# df_final.to_csv(os.path.join('data','Open-Meteo',f'all_prefectures_{year_start}_{year_end}_yearly.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_clim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
